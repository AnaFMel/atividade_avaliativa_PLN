{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Atividade Avaliativa - Processamento de Linguagem Natural**\n",
        "### **Equipe:** Ana Clara, Bruno, Igor e Pedro Cruz\n"
      ],
      "metadata": {
        "id": "tb_xoKytbTNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descrição e motivação do problema:**\n",
        "\n",
        "A disseminação de **fake news** tem acontecido com cada vez mais frequência e possui impacto significativo na sociedade, contribuindo para a desinformação, polarização social e decisões equivocadas. A motivação para desenvolver um algoritmo de identificação de notícias falsas está em promover uma sociedade mais informada, fornecendo as pessoas uma ferramenta automatizada para avaliar a veracidade de informações rapidamente. Isso pode ajudar a mitigar os efeitos negativos da desinformação, capacitando as pessoas a tomarem decisões mais conscientes e baseadas em fatos confiáveis."
      ],
      "metadata": {
        "id": "N35uvHTFb_vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descrição da base de dados (e do processo de obtenção dos dados, se for o caso):**\n",
        "\n",
        "A base de dados que decidimos utilizar é a [Fake.Br Corpus](https://github.com/roneysco/Fake.br-Corpus). Ela fornece pares de notícias verdadeiras e falsas em português.\n",
        "\n",
        "Mais especificamente, iremos utilizar os dados contidos na pasta \"size_normalized_texts\", que contém versões truncadas dos textos, onde em cada par verdadeiro-falso o texto mais longo é truncado (em número de palavras) para o tamanho do texto mais curto. Esta versão do corpus pode ser útil para evitar inclinações incorretas em experimentos de aprendizado de máquina."
      ],
      "metadata": {
        "id": "FVOFfOvPdNuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objetivo de negócio ou científico associado ao problema:**\n",
        "\n",
        "\n",
        "O objetivo científico deste projeto é desenvolver e validar um algoritmo capaz de identificar fake news de algum assunto específico com precisão. Já o objetivo de negócio é fornecer uma solução automatizada, como um chatbot, que permita organizações, jornalistas e usuários individuais verificarem rapidamente a veracidade de informações, reduzindo os impactos da desinformação em escala e promovendo a confiança em fontes confiáveis."
      ],
      "metadata": {
        "id": "XWYJXJcxdWII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pré-processamento & Extração de Características:**"
      ],
      "metadata": {
        "id": "o5gSBds0dlB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipando os arquivos baixados"
      ],
      "metadata": {
        "id": "o2QmvS_-pSr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "HOrERSulu7E_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caminho_zip = 'Fake.br-Corpus-master.zip'\n",
        "\n",
        "with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall('arquivos')"
      ],
      "metadata": {
        "id": "l5Lnbxo6oPjj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtendos os dados da pasta size_normalized_texts, como comentado anteriormente, e colocando tudo em um dataframe, inserindo o label 0 ou 1 para distinguirmos entre verdadeiro ou falso."
      ],
      "metadata": {
        "id": "8sac4bHEqEwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pzVf4y9ru5O0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_dir = 'arquivos/Fake.br-Corpus-master/size_normalized_texts/fake'\n",
        "true_dir = 'arquivos/Fake.br-Corpus-master/size_normalized_texts/true'\n",
        "\n",
        "def load_texts(directory, label):\n",
        "    data = []\n",
        "    for file in os.listdir(directory):\n",
        "        with open(os.path.join(directory, file), 'r', encoding='utf-8') as f:\n",
        "            data.append({'text': f.read(), 'label': label})\n",
        "    return data\n",
        "\n",
        "fake_data = load_texts(fake_dir, 0)  # 0 para \"falso\"\n",
        "true_data = load_texts(true_dir, 1)  # 1 para \"verdadeiro\"\n",
        "\n",
        "df = pd.DataFrame(fake_data + true_data)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P2-jiWnzpW2M",
        "outputId": "36e062b1-1b6f-45db-bbc8-62e64ac08f77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  A cor do luto será mudada pra cinza pra evitar...      0\n",
            "1  Joaquim Barbosa disse pretende disputar a\\nPre...      0\n",
            "2  Você vai se arrepiar! Durante show de rock,  p...      0\n",
            "3  URGENTE: Homem ameaça explodir prédio durante ...      0\n",
            "4  EUA lançam míssil nuclear da base de North Van...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploração"
      ],
      "metadata": {
        "id": "HuRnOUTYsbU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S8u1tlSzseSv",
        "outputId": "a28d7e96-e76e-4fa3-d108-7cbcfc042ecf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se temos algum nulo"
      ],
      "metadata": {
        "id": "ju7rVo1Asp7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vozOIenjsfLv",
        "outputId": "ad839136-2138-4fc3-9482-3d6346e440b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7200 entries, 0 to 7199\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    7200 non-null   object\n",
            " 1   label   7200 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 112.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento"
      ],
      "metadata": {
        "id": "DJDXPzowqgc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1cAB91WmdUiC",
        "outputId": "090ba759-fc67-4b63-c797-12915592758b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pickle"
      ],
      "metadata": {
        "id": "nZcx2xZyu2A9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
        "MAX_LEN = 128\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = bert_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u9lYS1XHqfYU",
        "outputId": "08a440fc-ec44-474b-f7cf-f68c7b95e779"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "def generate_embeddings_batchwise(texts, tokenizer, model, max_len, batch_size, device):\n",
        "    encoded = tokenizer(\n",
        "        texts,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    dataset = TensorDataset(encoded['input_ids'], encoded['attention_mask'])\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask in dataloader:\n",
        "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "            embeddings.append(cls_embedding.cpu().numpy())\n",
        "    return np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "dOB8XWYBrqvi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "print(\"Gerando embeddings...\")\n",
        "batch_size = 32\n",
        "embeddings = generate_embeddings_batchwise(texts, tokenizer, bert_model, MAX_LEN, batch_size, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "osXU_vcnt0-h",
        "outputId": "c1cd4141-f3b2-413e-94a7-a769f0550183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando embeddings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelos de Machine Learning:**"
      ],
      "metadata": {
        "id": "1dv8DrjOduyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Treinando o classificador...\")\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_XbP4Evxt6x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.naive_bayes import MultinomialNB\n",
        "#from sklearn.metrics import classification_report\n",
        "\n",
        "#vectorizer = TfidfVectorizer(max_features=5000)\n",
        "#X = vectorizer.fit_transform(df['processed_text']).toarray()\n",
        "#y = df['label']\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#model = MultinomialNB()\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "#y_pred = model.predict(X_test)\n",
        "#print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "0p8jlbyOxD40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Protocolo de experimentos e validação**"
      ],
      "metadata": {
        "id": "8xiN3HG2dy3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Avaliando o modelo...\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=['falso', 'verdadeiro']))"
      ],
      "metadata": {
        "id": "RMei79pit90b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIDENCE_THRESHOLD = 0.7\n",
        "\n",
        "def predict_with_threshold(text, tokenizer, model, classifier, max_len, device, threshold):\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    probas = classifier.predict_proba(cls_embedding)[0]\n",
        "    max_proba = np.max(probas)\n",
        "    if max_proba < threshold:\n",
        "        return \"Não sei\", max_proba\n",
        "    return (\"Verdadeiro\" if np.argmax(probas) == 1 else \"Falso\"), max_proba"
      ],
      "metadata": {
        "id": "SPGWROFbuKOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"EUA lançam míssil nuclear.\",\n",
        "    \"Brasil declara guerra.\",\n",
        "    \"Guitarrista atira no público durante show de rock.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    result, confidence = predict_with_threshold(\n",
        "        sentence, tokenizer, bert_model, classifier, MAX_LEN, device, CONFIDENCE_THRESHOLD\n",
        "    )\n",
        "    print(f\"Frase: {sentence}\")\n",
        "    print(f\"Resposta: {result}, Confiança: {confidence:.2f}\\n\")"
      ],
      "metadata": {
        "id": "bY8TwFT5uMYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discussão dos resultados e trabalhos futuros**"
      ],
      "metadata": {
        "id": "xjNEn42Vd2zW"
      }
    }
  ]
}